---
title: "Developing Data Products Demo"
author: "freestander"
date: "Saturday, October 24, 2015"
output: pdf_document
---

## Executive Summary

We want to build a model to predict the miles per gallon (MPG) by using a set of car features.

There is an "mtcars" dataset in R package. The data was extracted from the 1974 Motor Trend US magazine, and comprises fuel consumption and 10 aspects of automobile design and performance for 32 automobiles (1973-74 models).

## Exploratory Data Analysis 

First, we review each field in the dataset using the summary function and also draw a pariwise scattor plot between the variables (shown in appendix). 

```{r}
summary(mtcars)
```

## Data Preprocessing

Next, we transform some categorical variables into factor types to prepare for the regression analysis in the later steps.

```{r}
mtcars$cyl <- factor(mtcars$cyl)
mtcars$vs <- factor(mtcars$vs)
mtcars$am <- factor(mtcars$am, labels=c('Automatic','Manual'))
mtcars$gear <- factor(mtcars$gear)
mtcars$carb <- factor(mtcars$carb)
```

## Regression Model

We will use regression model to identify the variables that account for MPG differences. 

First, we try the multivariate linear regression with all variables included. The p-value is 0.000124, and the adjusted R-squared is 0.779, which means the model accounts for 77.9% variance. From the coefficients below, we can see some of the variables have insignificant p-value thus may bring noise to the model if included in the regression.

```{r}
m1 <- lm(mpg ~ ., data = mtcars)
summary(m1)
```

Next, we perform a stepwise model selection using backward elimination.

```{r, results='hide'}
m2 <- step(m1, direction="backward")
```

The remaining variables ("cyl", "hp", "wt", "am") are significant and fit the model best. The p-value is 1.506e-10, and the adjusted R-squared is 0.8401, which means the model accounts for 84.01% variance. Compared to automatic transmission, MPG increases by 1.8 if having a manual transmission. Moreover, the regression result shows MPG decreases -3.03 for "cyl6", -2.16 for "cyl8", -0.03 for "hp", -2.5 for "wt", respectively. 

```{r}
summary(m2)
```

We also do the residual plots (shown in appendix) to check how well the regression model fits. The "Residuals vs Fitted" plot shows no pattern, supporting the independence assumption. The "Normal Q-Q" plot shows that residuals can be approximated by normal distribution. The "Scale-Location" plot shows that the points are randomly distributed, supporting constant variance assumption. The "Residuals vs Leverage" plot shows that no particular outlier is observed.

## Conclusion

We can see that variables ("cyl", "hp", "wt", "am") fit the regression model best and and count for most MPG differences.

However, there are some limitations that we need to address to further improve the analysis result. For example, the residual plots show some transformation of the variables are needed to achieve linearity, and the sample size is too small (only 32 records) to arrive at a reliable conclusion.

## Appendix

The following is a pairwise scattor plot between different variables.

```{r}
pairs(mtcars, panel=panel.smooth, main="Pairwise Scattor Plot of Motor Trend Car Road Tests")
```

The following are the residual plots to check how well the regression model fits.

```{r}
par(mfrow = c(2, 2))
plot(m2)
```

## Source

Henderson and Velleman (1981), Building multiple regression models interactively. Biometrics, 37, 391-411.